{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '8,9'\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from safetensors.torch import load_file\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import dei_utils as Dei\n",
    "\n",
    "# model.model.layers[0].block_sparse_moe.gate.weight.data\n",
    "# model.model.layers[0].block_sparse_moe.experts[0].w1??\n",
    "# model.model.layers[0].block_sparse_moe.experts[0].w1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expert(layer):\n",
    "    json_file_path = \"/new_data/yanghq/models/mistralai/Mixtral-8x7B-Instruct-v0.1/model.safetensors.index.json\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data=data[\"weight_map\"]\n",
    "    shard_list=[]\n",
    "    for i in range(8):\n",
    "        for j in range(3):\n",
    "            weight_idx = f'model.layers.{layer}.block_sparse_moe.experts.{i}.w{j+1}.weight'\n",
    "            shard_path = data[weight_idx]\n",
    "            if shard_path not in shard_list:\n",
    "                shard_list.append(shard_path)\n",
    "    weight_dict={}\n",
    "    for shard_path in shard_list:\n",
    "        shard_path = f'/new_data/yanghq/models/mistralai/Mixtral-8x7B-v0.1/{shard_path}'\n",
    "        shard_weights = load_file(shard_path)\n",
    "        for i in range(8):\n",
    "            for j in range(3):\n",
    "                weight_idx = f'model.layers.{layer}.block_sparse_moe.experts.{i}.w{j+1}.weight'\n",
    "                if weight_idx in shard_weights.keys():\n",
    "                    weight_dict.update({weight_idx:shard_weights[weight_idx]})\n",
    "    return weight_dict\n",
    "    assert len(weight_dict) == 24\n",
    "    weight_list=[]\n",
    "    for w in weight_dict.values():\n",
    "        if w.shape[0] != 4096:\n",
    "            w=w.transpose(0,1)\n",
    "        weight_list.append(w)\n",
    "    weights=torch.stack(weight_list)\n",
    "    weights = weights.reshape([8,3,4096,-1])\n",
    "    # weights = weights.reshape([8,-1])\n",
    "    return weights\n",
    "a=get_expert(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([14336, 4096])\n",
      "torch.Size([4096, 14336])\n",
      "torch.Size([14336, 4096])\n"
     ]
    }
   ],
   "source": [
    "for i in a.values():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_router(layer):\n",
    "    json_file_path = \"/new_data/yanghq/models/mistralai/Mixtral-8x7B-Instruct-v0.1/model.safetensors.index.json\"\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    data=data[\"weight_map\"]\n",
    "    weight_idx = f'model.layers.{layer}.block_sparse_moe.gate.weight'\n",
    "    shard_path = data[weight_idx]\n",
    "    shard_path = f'/new_data/yanghq/models/mistralai/Mixtral-8x7B-v0.1/{shard_path}'\n",
    "    shard_weights = load_file(shard_path)\n",
    "    weights = shard_weights[weight_idx]\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 188.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tensor to /new_data/yanghq/data/dist/rou_cos.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 13/32 [01:15<01:46,  5.59s/it]"
     ]
    }
   ],
   "source": [
    "cos_sim = torch.zeros(32, 8, 8)\n",
    "for l in tqdm(range(32)):\n",
    "    data = get_router(l).to(torch.double)\n",
    "    for i in range(8):\n",
    "        for j in range(i+1):\n",
    "            cos_sim[l, i, j] = F.cosine_similarity(data[i].unsqueeze(0), data[j].unsqueeze(0))\n",
    "            cos_sim[l, j, i] = cos_sim[l, i, j]\n",
    "Dei.save(cos_sim, 'dist/rou_cos')\n",
    "\n",
    "cos_sim = torch.zeros(32, 8, 8)\n",
    "for l in tqdm(range(32)):\n",
    "    torch.cuda.empty_cache()\n",
    "    data = get_expert(l).to(torch.double).to('cuda:0')\n",
    "    for i in range(8):\n",
    "        for j in range(i+1):\n",
    "            cos_sim[l, i, j] = F.cosine_similarity(data[i].unsqueeze(0), data[j].unsqueeze(0))\n",
    "            cos_sim[l, j, i] = cos_sim[l, i, j]\n",
    "Dei.save(cos_sim, 'dist/exp_cos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 155.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tensor to /new_data/yanghq/data/dist/rou_mse.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [02:58<00:00,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving tensor to /new_data/yanghq/data/dist/exp_mse.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_sim = torch.zeros(32, 8, 8)\n",
    "for l in tqdm(range(32)):\n",
    "    data = get_router(l).to(torch.double)\n",
    "    for i in range(8):\n",
    "        for j in range(i+1):\n",
    "            diff = data[i] - data[j]\n",
    "            cos_sim[l, i, j] = torch.sum(diff ** 2) / diff.numel()\n",
    "            cos_sim[l, j, i] = cos_sim[l, i, j]\n",
    "Dei.save(cos_sim, 'dist/rou_mse')\n",
    "\n",
    "cos_sim = torch.zeros(32, 8, 8)\n",
    "for l in tqdm(range(32)):\n",
    "    torch.cuda.empty_cache()\n",
    "    data = get_expert(l).to(torch.double).to('cuda:0')\n",
    "    for i in range(8):\n",
    "        for j in range(i+1):\n",
    "            diff = data[i] - data[j]\n",
    "            cos_sim[l, i, j] = torch.sum(diff ** 2) / diff.numel()\n",
    "            cos_sim[l, j, i] = cos_sim[l, i, j]\n",
    "Dei.save(cos_sim, 'dist/exp_mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kivi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
